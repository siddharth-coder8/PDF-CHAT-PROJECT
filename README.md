# ğŸ“„ PDF Chatbot â€“ Ask Questions About Any PDF

An interactive Streamlit application that lets you upload a PDF, embed its contents using `OllamaEmbeddings`, and ask context-aware questions using a conversational AI powered by `phi`.

---

## ğŸš€ Features

* ğŸ“ Upload and parse PDFs
* ğŸ” Intelligent chunking of PDF content
* ğŸ§  Embedding with `OllamaEmbeddings` (LLM: `phi`)
* ğŸ’¾ Persistent `Chroma` vector store for fast retrieval
* ğŸ¤– LLM-powered question answering using `RetrievalQA`
* ğŸ’¬ Stateful conversation with memory
* ğŸ–¼ï¸ Chat UI with streaming responses and typing animation
* ğŸ”§ Robust error handling and logging

---

## ğŸ§± Tech Stack

* Python
* Streamlit
* LangChain
* Ollama (local LLM server)
* ChromaDB
* PyPDFLoader

---

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/siddharth-coder8/PDF-CHAT-PROJECT
cd PDF-CHAT-PROJECT

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows use venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## âš™ï¸ Requirements

* Python 3.8+
* [Ollama](https://ollama.com) running locally (tested with model `phi`)
* Required ports open (`http://localhost:11434` for Ollama)
* PDFs to test with

---

## ğŸ“‚ Folder Structure

```bash
.
â”œâ”€â”€ files/           # Uploaded PDFs
â”œâ”€â”€ jj/              # Chroma vector store
â”œâ”€â”€ main.py          # Main Streamlit app
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## â–¶ï¸ Usage

1. Start the Ollama server:

   ```bash
   ollama run phi
   ```

2. Run the app:

   ```bash
   streamlit run main.py
   ```

3. Upload a PDF and start chatting!

---

## ğŸ› ï¸ Troubleshooting

* If you see connection errors:

  * Make sure Ollama is running at `http://localhost:11434`
  * Ensure the `phi` model is downloaded
* Logs are printed to the terminal via `logging`
